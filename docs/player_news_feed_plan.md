# Player News Feed - Implementation Plan

## Overview

Build a unified news feed that:
- Aggregates content from RSS sources (starting with Floor and Ceiling Substack)
- Displays prominently on homepage ("Live Draft Buzz") and player detail pages
- Shows article images, AI-generated summaries, and "Read More at [Source]" CTAs
- Is designed to accommodate future non-RSS sources without over-engineering

---

## Key Design Decisions

| Decision | Rationale |
|----------|-----------|
| Abstract "source" from "feed type" | Sources table is feed-type-agnostic; RSS-specific logic lives in the ingestion service |
| Store raw + summarized content | Keep original title/description, add AI-generated `summary` field |
| Store image URLs directly | `image_url` on news items, not a separate table |
| AI summarization + classification | Single Gemini call generates both summary AND tag classification |
| AI on ingest, not on-demand | Process during ingestion to avoid latency on page load |

---

## Implementation Sequence

### Phase 1: Database Schema & Models

**New Files:**

1. `app/schemas/news_sources.py` - Source configuration (feed-type-agnostic)
   ```python
   class FeedType(str, Enum):
       RSS = "rss"
       # Future: API = "api", SCRAPER = "scraper", etc.

   class NewsSource(SQLModel, table=True):
       __tablename__ = "news_sources"

       id: Optional[int] = Field(default=None, primary_key=True)
       name: str = Field(index=True)                    # e.g., "Floor and Ceiling"
       display_name: str                                 # e.g., "Floor and Ceiling"
       feed_type: FeedType = Field(default=FeedType.RSS)
       feed_url: str = Field(unique=True)               # RSS URL or API endpoint
       is_active: bool = Field(default=True, index=True)
       fetch_interval_minutes: int = Field(default=30)
       last_fetched_at: Optional[datetime] = None
       created_at: datetime
       updated_at: datetime
   ```

2. `app/schemas/news_items.py` - News items table
   ```python
   class NewsItemTag(str, Enum):
       RISER = "Riser"
       FALLER = "Faller"
       ANALYSIS = "Analysis"
       HIGHLIGHT = "Highlight"

   class NewsItem(SQLModel, table=True):
       __tablename__ = "news_items"

       id: Optional[int] = Field(default=None, primary_key=True)
       source_id: int = Field(foreign_key="news_sources.id", index=True)
       external_id: str = Field(index=True)             # RSS guid for deduplication

       # Original content from feed
       title: str
       description: Optional[str] = None                # RSS description field
       url: str
       image_url: Optional[str] = None                  # From RSS enclosure
       author: Optional[str] = None                     # From dc:creator

       # AI-generated fields
       summary: Optional[str] = None                    # AI-generated byline

       # Classification
       tag: NewsItemTag = Field(default=NewsItemTag.ANALYSIS)

       # Timestamps
       published_at: datetime = Field(index=True)
       created_at: datetime

       # Future: player association
       player_id: Optional[int] = Field(default=None, foreign_key="players_master.id")

       # Unique constraint on (source_id, external_id)
   ```

3. `app/models/news.py` - Pydantic request/response models
   ```python
   class NewsItemRead(SQLModel):
       id: int
       source_name: str           # "Floor and Ceiling"
       title: str
       summary: str               # AI-generated byline
       url: str
       image_url: Optional[str]   # Article image or None for placeholder
       author: Optional[str]
       time: str                  # Relative time "2h", "1d"
       tag: str                   # "Riser", "Faller", etc.
       read_more_text: str        # "Read at Floor and Ceiling"
   ```

4. **Alembic migration** - Create both tables with proper indexes

---

### Phase 2: Service Layer

**New Files:**

1. `app/services/news_service.py` - Feed retrieval
   ```python
   async def get_news_feed(db, limit=20, offset=0) -> NewsFeedResponse:
       """Fetch paginated news with JOINed source info."""
       # Query news_items JOIN news_sources
       # Order by published_at DESC
       # Format relative time, build read_more_text
       pass

   def format_relative_time(dt: datetime) -> str:
       """Convert datetime to '2h', '1d', '3d', etc."""
       pass

   def build_read_more_text(source_name: str) -> str:
       """Generate 'Read at Floor and Ceiling' text."""
       return f"Read at {source_name}"
   ```

2. `app/services/news_ingestion_service.py` - Feed ingestion (abstracted)
   ```python
   async def run_ingestion_cycle(db: AsyncSession) -> dict:
       """Process all active sources based on their feed_type."""
       sources = await get_active_sources(db)
       for source in sources:
           if source.feed_type == FeedType.RSS:
               await ingest_rss_source(db, source)
           # Future: elif source.feed_type == FeedType.API: ...
       pass

   async def ingest_rss_source(db, source) -> int:
       """Fetch and parse RSS feed, analyze with AI, insert items."""
       entries = await fetch_rss_feed(source.feed_url)
       for entry in entries:
           # Extract: title, description, url, image_url (from enclosure), author
           # Call analyze_article() to get both summary AND tag in one AI call
           # Insert with deduplication
       pass

   async def fetch_rss_feed(url: str) -> List[dict]:
       """Parse RSS using feedparser, extract normalized fields."""
       # Use feedparser library
       # Extract enclosure URL for image_url
       # Extract dc:creator for author
       pass
   ```

3. `app/services/news_summarization_service.py` - AI summarization + classification
   ```python
   from pydantic import BaseModel

   class ArticleAnalysis(BaseModel):
       """Structured output from AI analysis."""
       summary: str      # 1-2 sentence compelling byline
       tag: NewsItemTag  # Riser, Faller, Analysis, or Highlight

   async def analyze_article(
       title: str,
       description: str,
       content: Optional[str] = None
   ) -> ArticleAnalysis:
       """
       Use Gemini to analyze an article and return both:
       1. A compelling 1-2 sentence summary/byline
       2. A classification tag (Riser/Faller/Analysis/Highlight)

       Prompt: "Analyze this NBA draft article and provide:
       1. A compelling 1-2 sentence summary that makes readers want to click
       2. A tag classification:
          - 'Riser' if about a player's stock rising or breakout performance
          - 'Faller' if about a player's stock falling or poor performance
          - 'Highlight' if about a standout game or impressive stats
          - 'Analysis' for general scouting reports or evaluations

       Title: {title}
       Description: {description}

       Respond as JSON: {\"summary\": \"...\", \"tag\": \"...\"}"
       """
       # Use existing Gemini client from app/services/image_generation.py pattern
       # Parse JSON response into ArticleAnalysis
       pass
   ```

**RSS Field Mapping (from Substack sample):**
| RSS Field | DB Field |
|-----------|----------|
| `<title>` | `title` |
| `<description>` | `description` |
| `<link>` | `url` |
| `<guid>` | `external_id` |
| `<pubDate>` | `published_at` |
| `<dc:creator>` | `author` |
| `<enclosure url="...">` | `image_url` |

---

### Phase 3: API Routes

**New File:** `app/routes/news.py`

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/news` | GET | Paginated news feed (limit, offset params) |
| `/api/news/sources` | GET | List RSS sources (admin) |
| `/api/news/sources` | POST | Add new RSS source (admin) |
| `/api/news/ingest` | POST | Trigger ingestion cycle (admin) |

Register router in `app/main.py`

---

### Phase 4: UI Integration

**Redesigned Feed Card Layout:**
```
┌─────────────────────────────────────────────────────────────┐
│  ┌──────────┐                                               │
│  │  IMAGE   │  TITLE (headline)                             │
│  │  120x80  │  AI-generated summary byline...               │
│  │          │                                               │
│  └──────────┘  [Tag Badge]  •  Author  •  2h ago            │
│                                                             │
│                          [ Read at Floor and Ceiling → ]    │
└─────────────────────────────────────────────────────────────┘
```

**Modify Existing Files:**

1. `app/routes/ui.py`
   - Update `home()` route to call `get_news_feed(db, limit=10)`
   - Update `player_detail()` route to call `get_news_feed(db, limit=5)`
   - Pass feed items with: title, summary, image_url, author, time, tag, url, read_more_text

2. `app/static/css/feed.css` (new) - Feed card styles
   ```css
   .feed-card {
     display: flex;
     gap: 1rem;
     padding: 1rem;
     background: white;
     border: 1px solid var(--color-slate-200);
     border-radius: 0.5rem;
   }
   .feed-card__image {
     width: 120px;
     height: 80px;
     object-fit: cover;
     border-radius: 0.25rem;
   }
   .feed-card__image--placeholder {
     background: var(--color-slate-100);
     /* DraftGuru placeholder pattern */
   }
   .feed-card__title { /* headline styles */ }
   .feed-card__summary { /* AI byline styles */ }
   .feed-card__meta { /* tag, author, time */ }
   .feed-card__cta { /* Read at [Source] button */ }
   ```

3. `app/static/js/home.js` - FeedModule
   - Render new card layout with image, summary, CTA button
   - Handle missing image_url with placeholder
   - Open links in new tab

4. `app/static/js/player-detail.js` - PlayerFeedModule
   - Same enhanced card layout

5. `app/templates/home.html` & `app/templates/player-detail.html`
   - Include new feed.css
   - Update feed container structure if needed

**Placeholder Image:**
- Create `/static/img/news-placeholder.svg` or use CSS-based placeholder
- Shows DraftGuru branding when article has no image

---

### Phase 5: Background Ingestion

**Approach:** Manual trigger endpoint + external cron

```bash
# Cron job (every 30 minutes)
*/30 * * * * curl -X POST https://draftguru.com/api/news/ingest
```

This avoids APScheduler complexity. The `/api/news/ingest` endpoint can be called manually for testing or by cron in production.

---

### Phase 6: Testing

**Unit Tests** (`tests/unit/test_news_service.py`):
- `format_relative_time()` edge cases
- Pydantic model validation
- `analyze_article()` (mock Gemini response for summary + tag)

**Integration Tests** (`tests/integration/test_news.py`):
- GET /api/news pagination
- POST /api/news/sources creates source
- POST /api/news/ingest runs without error
- News appears in homepage template context
- Feed cards render with image/placeholder correctly

**Fixtures to add to `conftest.py`:**
- `sample_news_source` - Test source fixture
- `sample_news_items` - Test news items with/without images

---

### Phase 7: Seed Data & Deployment

**Initial Sources** (all Substack RSS feeds):
```python
# Seed via migration or admin API
INITIAL_SOURCES = [
    {
        "name": "Floor and Ceiling",
        "display_name": "Floor and Ceiling",
        "feed_type": "rss",
        "feed_url": "https://floorandceiling.substack.com/feed",
    },
    # Add more Substack feeds as identified:
    # {
    #     "name": "Another Draft Substack",
    #     "display_name": "Another Draft Substack",
    #     "feed_type": "rss",
    #     "feed_url": "https://anotherdraft.substack.com/feed",
    # },
]
```

**Deployment Steps:**
1. Run Alembic migration to create tables
2. Seed initial Substack RSS sources
3. Trigger first ingestion cycle (generates AI summaries)
4. Verify end-to-end: Homepage and player pages show real news with images

---

## Dependencies

Add to `pyproject.toml`:
```toml
feedparser = ">=6.0.0"
```

---

## Key Files Reference

| File | Status | Purpose |
|------|--------|---------|
| `app/schemas/news_sources.py` | New | Source config table (feed-type-agnostic) |
| `app/schemas/news_items.py` | New | News items with images + AI summaries |
| `app/models/news.py` | New | Pydantic models |
| `app/services/news_service.py` | New | Feed retrieval logic |
| `app/services/news_ingestion_service.py` | New | Feed ingestion (abstracted for future types) |
| `app/services/news_summarization_service.py` | New | AI summary generation |
| `app/routes/news.py` | New | API endpoints |
| `app/routes/ui.py` | Modify | Replace hardcoded feed data |
| `app/static/css/feed.css` | New | Feed card styles |
| `app/static/js/home.js` | Modify | Enhanced feed card rendering |
| `app/static/js/player-detail.js` | Modify | Enhanced feed card rendering |
| `app/static/img/news-placeholder.svg` | New | Placeholder for articles without images |
| `app/main.py` | Modify | Register news router |
| `tests/integration/test_news.py` | New | Integration tests |
| `tests/unit/test_news_service.py` | New | Unit tests |

---

## Future Enhancements (Not in MVP)

- **Player-specific feed filtering** on player detail pages
- **Non-RSS sources** (API integrations, scrapers) - architecture supports this via `feed_type`
- **Admin UI** for managing sources
- **ML-based tag classification** (replace keyword matching)
- **Player name extraction** from article content for auto-tagging
- **Feed item caching/CDN**
- **Social sharing** of feed items
